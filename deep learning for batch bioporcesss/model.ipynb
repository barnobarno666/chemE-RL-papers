{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnesium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "class SDEEnv_train(gym.Env):\n",
    "    \"\"\" will remove the stoichastic part of the system \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SDEEnv_train, self).__init__()\n",
    "        # State is [y1, y2]\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(2,), dtype=np.float32)\n",
    "        \n",
    "        # Actions are [u1, u2], both in some control range\n",
    "        self.action_space = spaces.Box(low=0, high=10, shape=(2,), dtype=np.float32)\n",
    "        \n",
    "        # Time step for numerical integration\n",
    "        self.dt = 0.001\n",
    "        \n",
    "        # Initial values for state variables y1 and y2\n",
    "        self.state = np.array([1, 1])  # You can set this based on the problem\n",
    "        \n",
    "    def reset(self,seed = None,options = None):\n",
    "        # Reset the state to initial values\n",
    "        self.state = np.array([0.1, 0.1])\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        u1, u2 = action\n",
    "        y1, y2 = self.state\n",
    "        \n",
    "        dt = self.dt\n",
    "        \n",
    "        # Deterministic part of the system (first equation)\n",
    "        #dy1 = -(u1 + 0.5 * u1**2 * y1 + 0.5 * u2 * y2 / (y1 + y2)) * dt\n",
    "        dy1 = ( -1*(u1 + 0.5 * u1**2 )* y1 + 0.5 * u2 * y2 / (y1 + y2)) * dt\n",
    "\n",
    "        # Stochastic part of the second equation\n",
    "        dW = np.random.normal(0, np.sqrt(dt))  # Wiener process for stochastic term\n",
    "        dy2 = (u1 * y1 - 0.7 * u2 * y1) * dt + (0.1 * np.sqrt(y1)) \n",
    "        \n",
    "        \n",
    "        # Update states\n",
    "        y1 += dy1\n",
    "        y2 += dy2\n",
    "        \n",
    "        # Ensure non-negative concentrations\n",
    "        #y1 = max(0, y1)\n",
    "        #y2 = max(0, y2)\n",
    "        \n",
    "        self.state = np.array([y1, y2])\n",
    "        \n",
    "        # Reward is based on maximizing y2\n",
    "        reward = y2*10\n",
    "        \n",
    "        # Done if the system has run too long or if values go out of bounds\n",
    "        done = False\n",
    "        if y1 < .01 or y2 < .01:\n",
    "            reward = -1000\n",
    "            done = True\n",
    "        \n",
    "        return self.state, reward, done, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        # Optional rendering for visualization, not essential\n",
    "        print(f\"State: y1={self.state[0]}, y2={self.state[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SDEEnv_train_2(gym.Env):\n",
    "    \"\"\" nothing will change ,expcep that its stoichastic \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SDEEnv_train_2, self).__init__()\n",
    "        # State is [y1, y2]\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(2,), dtype=np.float32)\n",
    "        \n",
    "        # Actions are [u1, u2], both in some control range\n",
    "        self.action_space = spaces.Box(low=0, high=10, shape=(2,), dtype=np.float32)\n",
    "        \n",
    "        # Time step for numerical integration\n",
    "        self.dt = 0.001\n",
    "        \n",
    "        # Initial values for state variables y1 and y2\n",
    "        self.state = np.array([1, 1])  \n",
    "        \n",
    "    def reset(self,seed = None,options = None):\n",
    "        # Reset the state to initial values\n",
    "        self.state = np.array([0.1, 0.1])\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        u1, u2 = action\n",
    "        y1, y2 = self.state\n",
    "        \n",
    "        dt = self.dt\n",
    "        \n",
    "        # Deterministic part of the system (first equation)\n",
    "        dy1 = ( -1*(u1 + 0.5 * u1**2 )* y1 + 0.5 * u2 * y2 / (y1 + y2) ) * dt\n",
    "        \n",
    "        # Stochastic part of the second equation\n",
    "        dW = np.random.normal(0, np.sqrt(dt))  # Wiener process for stochastic term\n",
    "        dy2 = (u1 * y1 - 0.7 * u2 * y1) * dt + (0.1 * np.sqrt(y1) ) * dW\n",
    "        \n",
    "        \n",
    "        # Update states\n",
    "        y1 += dy1\n",
    "        y2 += dy2\n",
    "        \n",
    "        # Ensure non-negative concentrations\n",
    "        #y1 = max(0, y1)\n",
    "        #y2 = max(0, y2)\n",
    "        \n",
    "        self.state = np.array([y1, y2])\n",
    "        \n",
    "        # Reward is based on maximizing y2\n",
    "        reward = y2*100\n",
    "        \n",
    "        # Done if the system has run too long or if values go out of bounds\n",
    "        done = False\n",
    "        if y1 < 0 or y2 < 0:\n",
    "            reward = -1000\n",
    "            done = True\n",
    "        \n",
    "        return self.state, reward, done, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        # Optional rendering for visualization, not essential\n",
    "        print(f\"State: y1={self.state[0]}, y2={self.state[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
