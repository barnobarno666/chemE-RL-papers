{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "class Notreal(gym.Env):\n",
    "    \"\"\" will remove the stoichastic part of the system \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Notreal, self).__init__()\n",
    "        # State is [y1, y2]\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(3,), dtype=np.float64)\n",
    "        \n",
    "        # Actions are [u1, u2], both in some control range\n",
    "        self.action_space = spaces.Box(low=0, high=1000, shape=(2,), dtype=np.float64)\n",
    "        \n",
    "        # Time step for numerical integration\n",
    "        self.dt = 0.01\n",
    "        \n",
    "        # Initial values for state variables y1 and y2\n",
    "        self.state = np.array([1, 1])  # You  set this based on the problem\n",
    "        self.um= .0572\n",
    "        self.ud=0.0\n",
    "        self.Kn= 393.1\n",
    "        self.Ynx=504.1\n",
    "        self.km=.000016\n",
    "        self.kd=0.281\n",
    "        self.ks=178.9\n",
    "        self.ki=447.1\n",
    "        self.ksq=23.51\n",
    "        self.kiq=800\n",
    "        self.Knp=16.89\n",
    "        \n",
    "        #the manipulated variables are light intelfnsity I and inflow rate Fn\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def reset(self,seed = None,options = None):\n",
    "        # Reset the state to initial values\n",
    "        self.state = np.array([1 , 150 , 0]) #initial value can be changed, the bigger the value helps the model, but 0 is optimal\n",
    "        return self.state\n",
    "        \n",
    "        #change self. state ?\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        L, Fn = action\n",
    "        \n",
    "        cx,cn,cq = self.state\n",
    "        dt = self.dt\n",
    "        u_m=self.um\n",
    "        k_s=self.ks \n",
    "        K_N=self.Kn\n",
    "        k_i=self.ki\n",
    "        x=cx\n",
    "        n=cn \n",
    "        u_d=self.ud\n",
    "        Y_nx=self.Ynx\n",
    "        k_m=self.km\n",
    "        k_sq=self.ksq\n",
    "        k_iq=self.kiq\n",
    "        k_d=self.kd\n",
    "        q=cq\n",
    "        K_Np=self.Knp\n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "\n",
    "        dx   = u_m * L/(L+k_s+L**2./k_i) * x * n/(n+K_N) - u_d*x\n",
    "        dn   = - Y_nx*u_m* L/(L+k_s+L**2./k_i) * x * n/(n+K_N)+ Fn\n",
    "        dq   = (k_m * L/(L+k_sq+L**2./k_iq) * x - k_d * q/(n+K_Np)) * (np.sign(500. - n)+1)/2 * (np.sign(x - 10.0)+1)/2       \n",
    "         \n",
    "        # Update states\n",
    "        \n",
    "        cx+=dx * dt\n",
    "        cn+=dn * dt\n",
    "        cq+=dq * dt\n",
    "        \n",
    "        \n",
    "                \n",
    "        #so what is the sign function ? \n",
    "        \n",
    "        # Ensure non-negative concentrations\n",
    "        #y1 = max(0, y1)\n",
    "        #y2 = max(0, y2)\n",
    "        \n",
    "        self.state = np.array([cx,cn,cq])\n",
    "        \n",
    "        # Reward is based on maximizing y2\n",
    "        reward = cq * 10\n",
    "        \n",
    "        # Done if the system has run too long or if values go out of bounds\n",
    "        done = False\n",
    "        if cn<0  or cx < 0 or cq < 0 :\n",
    "            reward = -1000\n",
    "            done = True\n",
    "        \n",
    "        return self.state, reward, done, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        # Optional rendering for visualization, not essential\n",
    "        print(self.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#with added distrubences as stated in the paper, recheck the equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "class THIRD_ENV_WITH_DISTURBENCE(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(THIRD_ENV_WITH_DISTURBENCE, self).__init__()\n",
    "\n",
    "        # State space: concentrations of biomass (C_X), nitrate (C_N), and product (C_q)\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(3,), dtype=np.float32)\n",
    "        \n",
    "        # Action space: light intensity (I) and inflow rate (F_N)\n",
    "        self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([400, 40]), dtype=np.float32)\n",
    "\n",
    "        # Initial states\n",
    "        self.state = None\n",
    "        self.time_step = 0\n",
    "        self.max_time_steps = 10  # Define the number of time steps in the batch\n",
    "\n",
    "        # Disturbance and noise parameters\n",
    "        self.sigma_d = np.array([4e-3, 1.0, 1e-7])  # \n",
    "        self.sigma_n = np.array([4e-4, 0.1, 1e-8])  \n",
    "\n",
    "        \n",
    "        self.penalty_coefficients = np.array([3.125e-8, 3.125e-6])\n",
    "\n",
    "    def reset(self):\n",
    "        # Initial concentrations (state)\n",
    "        self.state = np.array([1.0, 150.0, 0.0], dtype=np.float32)\n",
    "        self.time_step = 0\n",
    "        return self.state + np.random.normal(0, self.sigma_n)  # Add initial measurement noise\n",
    "\n",
    "    def step(self, action):\n",
    "        # Apply system dynamics and additive disturbance\n",
    "        I, F_N = action\n",
    "\n",
    "        C_X, C_N, C_q = self.state\n",
    "\n",
    "        dC_X = (I / (I + 178.9)) * C_X * (C_N / (C_N + 393.1)) - 0.0572 * C_X\n",
    "        dC_N = -504.1 * (I / (I + 178.9)) * C_X * (C_N / (C_N + 393.1)) + F_N\n",
    "        dC_q = (0.00016 * (I / (I + 23.51)) * C_X * (C_N / (C_N + 393.1))) if C_N <= 500 and C_X >= 10 else 0\n",
    "\n",
    "        # Add additive disturbances to the dynamics\n",
    "        disturbance = np.sin(self.time_step) * self.sigma_d + np.random.normal(0, self.sigma_d)\n",
    "        \n",
    "        dC_X += disturbance[0]\n",
    "        dC_N += disturbance[1]\n",
    "        dC_q += disturbance[2]\n",
    "\n",
    "        # Update state with dynamics and disturbances\n",
    "        self.state += np.array([dC_X, dC_N, dC_q])\n",
    "\n",
    "        # Add measurement noise when observing the state\n",
    "        noisy_state = self.state + np.random.normal(0, self.sigma_n)\n",
    "\n",
    "        if self.time_step < self.max_time_steps - 1:\n",
    "            reward = -np.dot(action - np.zeros(2), self.penalty_coefficients * (action - np.zeros(2)))\n",
    "        else:\n",
    "            reward = self.state[2]  # Final product concentration (C_q)\n",
    "\n",
    "        self.time_step += 1\n",
    "        done = self.time_step >= self.max_time_steps\n",
    "\n",
    "        return noisy_state, reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
